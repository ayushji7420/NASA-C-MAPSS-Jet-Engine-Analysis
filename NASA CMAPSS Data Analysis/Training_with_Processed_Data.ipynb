{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f74d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd41958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_format_Conversion(train_no, engine_id):\n",
    "    df = pd.read_csv(\"Processed Data for RUL Pred/Processed_train_FD00{}.csv\".format(train_no))\n",
    "    train = df[df[\"ID\"]==engine_id]\n",
    "    train = train.drop(columns=[\"ID\"])\n",
    "\n",
    "    scaler=MinMaxScaler()\n",
    "    df = scaler.fit_transform(df)\n",
    "    print('Shape of df for engine {}: '.format(engine_id),df.shape)\n",
    "\n",
    "    features = train.iloc[:, :-1]\n",
    "    target = train.iloc[:, -1]\n",
    "\n",
    "    ts_generator = TimeseriesGenerator(features,target,length=win_length,sampling_rate=1,batch_size=1)\n",
    "\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for i in range(len(ts_generator)):\n",
    "        x_temp, y_temp = ts_generator[i]\n",
    "        X.append(x_temp.reshape(x_temp.shape[1],x_temp.shape[2],1))\n",
    "        y.append(y_temp)\n",
    "\n",
    "    X=np.array(X)  \n",
    "    y=np.array(y)  \n",
    "    \n",
    "    return(X,y,scaler,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c6ce4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m model=Sequential()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# CNN\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model.add(Input(Shape=(win_length,feature_num,\u001b[32m1\u001b[39m)))\n\u001b[32m      7\u001b[39m model.add(Conv2D(filters=\u001b[32m64\u001b[39m, kernel_size=\u001b[32m3\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      8\u001b[39m model.add(Conv2D(filters=\u001b[32m32\u001b[39m, kernel_size=\u001b[32m3\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "win_length = 25   ######### Sliding Window Length\n",
    "feature_num = 13  ######### Total number of features\n",
    "\n",
    "model=Sequential()\n",
    "# CNN\n",
    "model.add(Input(Shape=(win_length,feature_num,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e458a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df for engine 1:  (20631, 15)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m engine_no \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,\u001b[32m50\u001b[39m):    \n\u001b[32m      3\u001b[39m     X,y,scaler,features=Data_format_Conversion(Train_no,engine_no) \n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     model.fit(X,y,steps_per_epoch=\u001b[32m5\u001b[39m,epochs=\u001b[32m15\u001b[39m,shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,verbose=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayush Sharma\\miniconda3\\envs\\ml-env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ayush Sharma\\miniconda3\\envs\\ml-env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:133\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m    132\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.experimental.Optional.from_value(\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m             one_step_on_data(iterator.get_next())\n\u001b[32m    134\u001b[39m         )\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[32m    137\u001b[39m     empty_outputs = tf.experimental.Optional.empty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "Train_no=1\n",
    "for engine_no in range(1,50):    \n",
    "    X,y,scaler,features=Data_format_Conversion(Train_no,engine_no) \n",
    "    \n",
    "    model.fit(X,y,steps_per_epoch=5,epochs=15,shuffle=False,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ecc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_no=1\n",
    "\n",
    "\n",
    "m = np.random.randint(low=1,high=60,size=5) \n",
    "\n",
    "for i in m:    \n",
    "    engine_id=i\n",
    "    X,y,scaler,features=Data_format_conversion(Train_no,engine_id) \n",
    "\n",
    "    prediction=model.predict(X) ######### prediction on trained data\n",
    "    rev_trans =pd.concat([pd.DataFrame(features[win_length:]),pd.DataFrame(prediction)],axis=1)\n",
    "    rev_trans = scaler.inverse_transform(rev_trans)######## Transforming back to original scale\n",
    "    rev_trans =pd.DataFrame(rev_trans)\n",
    "\n",
    "    \n",
    "    df=pd.read_csv(\"Processed_Train_00{}.csv\".format(Train_no))\n",
    "    df = df[df['ID']==engine_id]\n",
    "    df_actual = df.drop(columns=['ID'])\n",
    "\n",
    "\n",
    "    print('RMSE on This set:', np.sqrt(metrics.mean_squared_error(df_actual['RUL'][win_length:],rev_trans[13])))\n",
    "\n",
    "    plt.plot(df_actual['Cycle'][win_length:],df_actual['RUL'][win_length:])\n",
    "    plt.plot(rev_trans[0],rev_trans[13])\n",
    "    plt.ylabel('RUL')\n",
    "    plt.xlabel('CYCLE')\n",
    "    plt.title('Engine No is: {}'.format(engine_no))\n",
    "    plt.legend([ 'Actual','Prediction'], loc='upper right')\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_no=2\n",
    "\n",
    "n = np.random.randint(low=61,high=100,size=25) \n",
    "\n",
    "for i in n:    \n",
    "    engine_id=i\n",
    "    X,y,scaler,features=Data_format_conversion(Train_no,engine_id) \n",
    "\n",
    "    prediction=model.predict(X) ######### prediction on trained data\n",
    "    rev_trans =pd.concat([pd.DataFrame(features[win_length:]),pd.DataFrame(prediction)],axis=1)\n",
    "    rev_trans = scaler.inverse_transform(rev_trans)######## Transforming back to original scale\n",
    "    rev_trans =pd.DataFrame(rev_trans)\n",
    "\n",
    "    df=pd.read_csv(\"Processed_Train_00{}.csv\".format(Train_no))\n",
    "    df = df[df['ID']==engine_id]\n",
    "    df_actual = df.drop(columns=['ID'])\n",
    "\n",
    "\n",
    "    print('RMSE on This set:', np.sqrt(metrics.mean_squared_error(df_actual['RUL'][win_length:],rev_trans[13])))\n",
    "\n",
    "    plt.plot(df_actual['Cycle'][win_length:],df_actual['RUL'][win_length:])\n",
    "    plt.plot(rev_trans[0],rev_trans[13])\n",
    "    plt.ylabel('RUL')\n",
    "    plt.xlabel('CYCLE')\n",
    "    plt.title('Engine No is: {}'.format(engine_no))\n",
    "    plt.legend([ 'Actual','Prediction'], loc='upper right')\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
